version: '3'

services:
  web:
    image: llmproject_web
    build:
      context: ./images/llmproject_image
      dockerfile: ${PWD}/images/llmproject_image/Dockerfile
    logging:
      driver: "json-file"
    environment:
      TZ: 'Asia/Taipei'
      WEBROOT: '/var/www/html/LLM_Project/public'
      PHP_REDIS_SESSION_HOST: 'redis'
      CREATE_LARAVEL_STORAGE: '1'
      COMPOSERMIRROR: 'https://mirrors.cloud.tencent.com/composer/'
      NPMMIRROR: 'https://registry.npmmirror.com'
    ports:
      - "8080:80"
      - "443:443"
      - "9000:9000"
    volumes:
      - ../web:/var/www/html/LLM_Project
      - ./script:/script
      - ./ssl:/ssl
      - ../LLMs/agent:/agent
    networks:
      - taide
    depends_on:
      - db
      - redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/v1.0/worker/debug"]
      interval: 15s
      timeout: 5s
      retries: 10
  db:
    image: postgres
    restart: always
    environment:
      POSTGRES_PASSWORD: LLMProject
      POSTGRES_USER: llmprojectroot
      POSTGRES_DB: llm_project
    ports:
      - "5432:5432"
    networks:
      - taide
    volumes:
      - ./db_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U llmprojectroot -d llm_project -t 1"]
      interval: 10s
      timeout: 5s
      retries: 5
  redis:
    image: redis:7.0-alpine
    restart: always
    networks:
      - taide
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
  api_debug_01:
    runtime: nvidia
    image: api
    build:
      context: ./images/API_image
      dockerfile: ${PWD}/images/API_image/Dockerfile
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]
    volumes:
      - ./api_debug:/API
    depends_on:
      - web
    networks:
      - taide
    healthcheck:
      test: ["CMD", "curl", "-X", "POST", "-f", "http://localhost:9001/"]
      interval: 10s
      timeout: 5s
      retries: 5
  api:
    runtime: nvidia
    image: api
    build:
      context: ./images/API_image
      dockerfile: ${PWD}/images/API_image/Dockerfile
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]
    volumes:
      - ./APIs:/API
    depends_on:
      - web
    networks:
      - taide
    healthcheck:
      test: ["CMD", "curl", "-X", "POST", "-f", "http://localhost:9001/"]
      interval: 10s
      timeout: 5s
      retries: 5
  api_worker:
    runtime: nvidia
    image: doc-qa
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ["0"]
            capabilities: [gpu]
    env_file: data/doc-qa/.env.prod
    environment:
      - LLM_NAME=db_qa
      - PORT=9001
      - LAYOUT_CONFIG=layout_dbqa.yaml
    volumes:
      - ./APIs/TAIDE-LLaMA2-7B-chat-b.1.0.0/llama2-7b_tv_noemb_chat_tokenizer=ccw|stage=2|data=j|epoch=0-step=12740:/llm/:ro
      - ./data/doc-qa/database:/database/:ro
      - ./data/doc-qa/log:/var/log/doc_qa
    depends_on:
      - web
    networks:
      - taide
    healthcheck:
      test: "curl --fail http://localhost:9001/health || exit 1"
      interval: 10s
      timeout: 5s
      retries: 5


networks:
  taide:
